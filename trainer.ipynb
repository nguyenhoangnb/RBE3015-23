{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-12T02:44:12.637433Z",
     "start_time": "2024-12-12T02:44:08.896661Z"
    }
   },
   "source": [
    "import ultralytics\n",
    "import torch"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\delta\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T02:46:37.812141Z",
     "start_time": "2024-12-12T02:46:37.807237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "            self,\n",
    "            lr=0.001,\n",
    "            epochs=200,\n",
    "            patience=25,\n",
    "            dropout=0.2,\n",
    "            weight_decay=0.0001,\n",
    "            batch_size=16,\n",
    "            device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            data_path='datasets/dip_dataset/data.yaml'\n",
    "    ):\n",
    "        # Training using cpu or gpu\n",
    "        self.device = device\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weight_decay = weight_decay\n",
    "        self.patience = patience\n",
    "        self.dropout = dropout\n",
    "        self.batch_size = batch_size\n",
    "        self.data_path = data_path\n",
    "\n",
    "        # NN model\n",
    "        self.model = ultralytics.YOLO('yolov8n.pt').to(self.device)\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train(\n",
    "            data=self.data_path,\n",
    "            epochs=self.epochs,\n",
    "            batch=self.batch_size,\n",
    "            patience=self.patience,\n",
    "            optimizer='Adam',\n",
    "            lr0=self.lr,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n"
   ],
   "id": "23c397b9b56e3a55",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T03:03:24.104014Z",
     "start_time": "2024-12-12T02:51:26.168060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(data_path='dip_dataset/data.yaml')\n",
    "trainer.train()"
   ],
   "id": "f1954e3a13c263c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mengine\\trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.pt, data=dip_dataset/data.yaml, epochs=200, time=None, patience=25, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train7\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\delta\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 3.11MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    755992  ultralytics.nn.modules.head.Detect           [24, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3,015,528 parameters, 3,015,512 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001B[34m\u001B[1mAMP: \u001B[0mchecks failed . AMP training on NVIDIA GeForce GTX 1650 GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning Q:\\study\\Xu_ly_anh_va_thi_giac_Robot\\final_exam\\dip_dataset\\train\\labels... 608 images, 0 backgrounds, 0 corrupt: 100%|██████████| 608/608 [00:00<00:00, 983.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: Q:\\study\\Xu_ly_anh_va_thi_giac_Robot\\final_exam\\dip_dataset\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mScanning Q:\\study\\Xu_ly_anh_va_thi_giac_Robot\\final_exam\\dip_dataset\\valid\\labels... 100 images, 0 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:00<00:00, 512.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: Q:\\study\\Xu_ly_anh_va_thi_giac_Robot\\final_exam\\dip_dataset\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train7\\labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m Adam(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0001), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001B[1mruns\\detect\\train7\u001B[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/200      8.27G      2.263      3.699      1.159       3390        640: 100%|██████████| 38/38 [03:50<00:00,  6.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 2/4 [00:13<00:13,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:24<00:00,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        100      18902    0.00855     0.0189    0.00581    0.00271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/200      9.79G      2.135      2.905      1.115       4149        640: 100%|██████████| 38/38 [03:53<00:00,  6.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:23<00:00,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        100      18902     0.0219     0.0527     0.0274     0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/200      9.25G      2.076      2.649      1.099       4259        640:  39%|███▉      | 15/38 [01:42<02:37,  6.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(data_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdip_dataset/data.yaml\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m trainer\u001B[38;5;241m.\u001B[39mtrain()\n",
      "Cell \u001B[1;32mIn[9], line 29\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 29\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain(\n\u001B[0;32m     30\u001B[0m         data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_path,\n\u001B[0;32m     31\u001B[0m         epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepochs,\n\u001B[0;32m     32\u001B[0m         batch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size,\n\u001B[0;32m     33\u001B[0m         patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatience,\n\u001B[0;32m     34\u001B[0m         optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAdam\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     35\u001B[0m         lr0\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr,\n\u001B[0;32m     36\u001B[0m         weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight_decay,\n\u001B[0;32m     37\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\ultralytics\\engine\\model.py:806\u001B[0m, in \u001B[0;36mModel.train\u001B[1;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[0;32m    803\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mmodel\n\u001B[0;32m    805\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mhub_session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession  \u001B[38;5;66;03m# attach optional HUB session\u001B[39;00m\n\u001B[1;32m--> 806\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m    807\u001B[0m \u001B[38;5;66;03m# Update model and cfg after training\u001B[39;00m\n\u001B[0;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m}:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:207\u001B[0m, in \u001B[0;36mBaseTrainer.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    204\u001B[0m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(file))\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 207\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_train(world_size)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:380\u001B[0m, in \u001B[0;36mBaseTrainer._do_train\u001B[1;34m(self, world_size)\u001B[0m\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mamp):\n\u001B[0;32m    379\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess_batch(batch)\n\u001B[1;32m--> 380\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_items \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(batch)\n\u001B[0;32m    381\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    382\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m world_size\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:111\u001B[0m, in \u001B[0;36mBaseModel.forward\u001B[1;34m(self, x, *args, **kwargs)\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;124;03mPerform forward pass of the model for either training or inference.\u001B[39;00m\n\u001B[0;32m     99\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001B[39;00m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mdict\u001B[39m):  \u001B[38;5;66;03m# for cases of training and validating while training.\u001B[39;00m\n\u001B[1;32m--> 111\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:293\u001B[0m, in \u001B[0;36mBaseModel.loss\u001B[1;34m(self, batch, preds)\u001B[0m\n\u001B[0;32m    290\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_criterion()\n\u001B[0;32m    292\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;28;01mif\u001B[39;00m preds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m preds\n\u001B[1;32m--> 293\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion(preds, batch)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\ultralytics\\utils\\loss.py:234\u001B[0m, in \u001B[0;36mv8DetectionLoss.__call__\u001B[1;34m(self, preds, batch)\u001B[0m\n\u001B[0;32m    230\u001B[0m pred_bboxes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbbox_decode(anchor_points, pred_distri)  \u001B[38;5;66;03m# xyxy, (b, h*w, 4)\u001B[39;00m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;66;03m# dfl_conf = pred_distri.view(batch_size, -1, 4, self.reg_max).detach().softmax(-1)\u001B[39;00m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;66;03m# dfl_conf = (dfl_conf.amax(-1).mean(-1) + dfl_conf.amax(-1).amin(-1)) / 2\u001B[39;00m\n\u001B[1;32m--> 234\u001B[0m _, target_bboxes, target_scores, fg_mask, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39massigner(\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;66;03m# pred_scores.detach().sigmoid() * 0.8 + dfl_conf.unsqueeze(-1) * 0.2,\u001B[39;00m\n\u001B[0;32m    236\u001B[0m     pred_scores\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39msigmoid(),\n\u001B[0;32m    237\u001B[0m     (pred_bboxes\u001B[38;5;241m.\u001B[39mdetach() \u001B[38;5;241m*\u001B[39m stride_tensor)\u001B[38;5;241m.\u001B[39mtype(gt_bboxes\u001B[38;5;241m.\u001B[39mdtype),\n\u001B[0;32m    238\u001B[0m     anchor_points \u001B[38;5;241m*\u001B[39m stride_tensor,\n\u001B[0;32m    239\u001B[0m     gt_labels,\n\u001B[0;32m    240\u001B[0m     gt_bboxes,\n\u001B[0;32m    241\u001B[0m     mask_gt,\n\u001B[0;32m    242\u001B[0m )\n\u001B[0;32m    244\u001B[0m target_scores_sum \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(target_scores\u001B[38;5;241m.\u001B[39msum(), \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    246\u001B[0m \u001B[38;5;66;03m# Cls loss\u001B[39;00m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;66;03m# loss[1] = self.varifocal_loss(pred_scores, target_scores, target_labels) / target_scores_sum  # VFL way\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\ultralytics\\utils\\tal.py:74\u001B[0m, in \u001B[0;36mTaskAlignedAssigner.forward\u001B[1;34m(self, pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m     66\u001B[0m         torch\u001B[38;5;241m.\u001B[39mfull_like(pd_scores[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbg_idx),\n\u001B[0;32m     67\u001B[0m         torch\u001B[38;5;241m.\u001B[39mzeros_like(pd_bboxes),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     70\u001B[0m         torch\u001B[38;5;241m.\u001B[39mzeros_like(pd_scores[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m0\u001B[39m]),\n\u001B[0;32m     71\u001B[0m     )\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 74\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward(pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt)\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mOutOfMemoryError:\n\u001B[0;32m     76\u001B[0m     \u001B[38;5;66;03m# Move tensors to CPU, compute, then move back to original device\u001B[39;00m\n\u001B[0;32m     77\u001B[0m     LOGGER\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWARNING: CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\ultralytics\\utils\\tal.py:102\u001B[0m, in \u001B[0;36mTaskAlignedAssigner._forward\u001B[1;34m(self, pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt)\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, pd_scores, pd_bboxes, anc_points, gt_labels, gt_bboxes, mask_gt):\n\u001B[0;32m     83\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;124;03m    Compute the task-aligned assignment. Reference code is available at\u001B[39;00m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;124;03m    https://github.com/Nioolek/PPYOLOE_pytorch/blob/master/ppyoloe/assigner/tal_assigner.py.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;124;03m        target_gt_idx (Tensor): shape(bs, num_total_anchors)\u001B[39;00m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 102\u001B[0m     mask_pos, align_metric, overlaps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_pos_mask(\n\u001B[0;32m    103\u001B[0m         pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt\n\u001B[0;32m    104\u001B[0m     )\n\u001B[0;32m    106\u001B[0m     target_gt_idx, fg_mask, mask_pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mselect_highest_overlaps(mask_pos, overlaps, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_max_boxes)\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;66;03m# Assigned target\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\ultralytics\\utils\\tal.py:124\u001B[0m, in \u001B[0;36mTaskAlignedAssigner.get_pos_mask\u001B[1;34m(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, anc_points, mask_gt)\u001B[0m\n\u001B[0;32m    122\u001B[0m mask_in_gts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mselect_candidates_in_gts(anc_points, gt_bboxes)\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Get anchor_align metric, (b, max_num_obj, h*w)\u001B[39;00m\n\u001B[1;32m--> 124\u001B[0m align_metric, overlaps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_box_metrics(pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_in_gts \u001B[38;5;241m*\u001B[39m mask_gt)\n\u001B[0;32m    125\u001B[0m \u001B[38;5;66;03m# Get topk_metric mask, (b, max_num_obj, h*w)\u001B[39;00m\n\u001B[0;32m    126\u001B[0m mask_topk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mselect_topk_candidates(align_metric, topk_mask\u001B[38;5;241m=\u001B[39mmask_gt\u001B[38;5;241m.\u001B[39mexpand(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtopk)\u001B[38;5;241m.\u001B[39mbool())\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dip\\Lib\\site-packages\\ultralytics\\utils\\tal.py:146\u001B[0m, in \u001B[0;36mTaskAlignedAssigner.get_box_metrics\u001B[1;34m(self, pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_gt)\u001B[0m\n\u001B[0;32m    143\u001B[0m bbox_scores[mask_gt] \u001B[38;5;241m=\u001B[39m pd_scores[ind[\u001B[38;5;241m0\u001B[39m], :, ind[\u001B[38;5;241m1\u001B[39m]][mask_gt]  \u001B[38;5;66;03m# b, max_num_obj, h*w\u001B[39;00m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;66;03m# (b, max_num_obj, 1, 4), (b, 1, h*w, 4)\u001B[39;00m\n\u001B[1;32m--> 146\u001B[0m pd_boxes \u001B[38;5;241m=\u001B[39m pd_bboxes\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mexpand(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_max_boxes, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)[mask_gt]\n\u001B[0;32m    147\u001B[0m gt_boxes \u001B[38;5;241m=\u001B[39m gt_bboxes\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mexpand(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, na, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)[mask_gt]\n\u001B[0;32m    148\u001B[0m overlaps[mask_gt] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miou_calculation(gt_boxes, pd_boxes)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
